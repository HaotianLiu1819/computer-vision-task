{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import autoaugment\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import contextlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cifar10_loaders(\n",
    "    batch_size: int         = 256, \n",
    "    num_workers: int        = 8,  \n",
    "    pin_memory: bool        = True,\n",
    "    persistent_workers: bool = True, \n",
    "):\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        autoaugment.AutoAugment(autoaugment.AutoAugmentPolicy.CIFAR10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                             (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                             (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', train=True, download=True, transform=transform_train\n",
    "    )\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        persistent_workers=persistent_workers,\n",
    "        drop_last=True,              \n",
    "    )\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', train=False, download=True, transform=transform_test\n",
    "    )\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        persistent_workers=persistent_workers,\n",
    "    )\n",
    "\n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1)\n",
    "        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        w = self.global_avg_pool(x)\n",
    "        w = self.relu(self.fc1(w))\n",
    "        w = 2 * self.sigmoid(self.fc2(w))\n",
    "        return x * w "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleneckBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, max_depth=3, reduction_factor=4):\n",
    "        super(BottleneckBlock, self).__init__()\n",
    "\n",
    "        reduced_channels = in_channels // reduction_factor\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, reduced_channels, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.GroupNorm(1, in_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(reduced_channels, reduced_channels, kernel_size=3, stride=1, padding=1, bias=False, groups=reduced_channels)\n",
    "        self.bn2 = nn.GroupNorm(1, reduced_channels)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(reduced_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.GroupNorm(1, reduced_channels)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.skip_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.skip_bn = nn.GroupNorm(1, in_channels)\n",
    "\n",
    "        self.se = SEBlock(out_channels)\n",
    "\n",
    "    def forward(self, x, depth):\n",
    "        identity = x\n",
    "\n",
    "        out = self.relu(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.conv1(out)\n",
    "\n",
    "        out = self.relu(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out = self.relu(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.conv3(out)\n",
    "\n",
    "        out = self.se(out)\n",
    "\n",
    "        skip = self.relu(identity)\n",
    "        skip = self.skip_bn(skip)\n",
    "        skip = self.skip_conv(skip)\n",
    "\n",
    "        out += skip\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmplifyConv(nn.Module):\n",
    "    def __init__(self, channels, max_depth=3, num_module=2):\n",
    "        super(AmplifyConv, self).__init__()\n",
    "        self.max_depth = max_depth\n",
    "        self.num_module = num_module\n",
    "\n",
    "        self.conv = nn.ModuleList([\n",
    "            BottleneckBlock(channels, channels, max_depth) for _ in range(num_module)\n",
    "        ])\n",
    "        self.bn = nn.GroupNorm(1, channels)\n",
    "\n",
    "        self.step_embeddings = nn.Parameter(torch.randn(max_depth, channels, 1, 1))\n",
    "        self.step_embeddings1 = nn.Parameter(torch.randn(max_depth, channels, 1, 1))\n",
    "        self.step_embeddings2 = nn.Parameter(torch.randn(max_depth, channels, 1, 1))\n",
    "\n",
    "    def step_forward(self, x, x_prev, depth):\n",
    "        out = self.conv[depth // (self.max_depth // self.num_module)](x, depth)\n",
    "        x = 2 * F.sigmoid(self.step_embeddings1[depth]) * F.relu(x) + (1 + self.step_embeddings[depth]) * out\n",
    "        x = self.bn(x)\n",
    "\n",
    "        if depth < self.max_depth - 1:\n",
    "            x = x + 2 * F.sigmoid(self.step_embeddings2[depth]) * F.relu(x_prev)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        prev = []\n",
    "        for d in range(self.max_depth):\n",
    "            if d % 2 == 0:\n",
    "                prev.append(x)\n",
    "                \n",
    "            x_prev = prev[((d + 1) - ((d + 1) & -(d + 1))) // 2]\n",
    "            x = checkpoint(self.step_forward, x, x_prev, d, use_reentrant=False)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecursionAmplifyConv(nn.Module):\n",
    "    def __init__(self, channels, height, width):\n",
    "        super(RecursionAmplifyConv, self).__init__()\n",
    "        \n",
    "        self.conv0 = nn.Conv2d(3, channels, kernel_size=4, stride=2, padding=1)\n",
    "        self.amconv = AmplifyConv(channels, max_depth=32, num_module=1)\n",
    "        \n",
    "        self.max_pool = nn.AdaptiveMaxPool2d((1, 1))\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv0(x)\n",
    "\n",
    "        x = self.amconv(x)\n",
    "\n",
    "        x = torch.cat([self.max_pool(x), self.avg_pool(x)], dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.reamconv= RecursionAmplifyConv(512, 32, 32)\n",
    "\n",
    "        self.fc1 = nn.Linear(1024, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.reamconv(x)\n",
    "        \n",
    "        x = x.contiguous().view(-1, 1024)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RL_fine_tune:\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "    def compute_reconstruct_reward(self, outputs, targets):\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        correct = (predictions == targets).float()\n",
    "        \n",
    "        rewards = (correct - 0.5)\n",
    "    \n",
    "        return rewards, correct.sum().item()\n",
    "\n",
    "    def compute_positive_reward(self, outputs, targets):\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        correct = (predictions == targets).float()\n",
    "        \n",
    "        rewards = correct\n",
    "    \n",
    "        return rewards, correct.sum().item()\n",
    "\n",
    "    def compute_negative_reward(self, outputs, targets):\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        correct = (predictions == targets).float()\n",
    "        \n",
    "        rewards = (correct - 1)\n",
    "    \n",
    "        return rewards, correct.sum().item()\n",
    "\n",
    "    \n",
    "    def emergency_policy_loss(self, ref_outputs, pre_outputs, outputs, targets):\n",
    "        \n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "        select = - F.log_softmax(outputs, dim=1).gather(1, targets.unsqueeze(1)).squeeze(1)\n",
    "        entropy = torch.sum(probs * torch.log(probs), dim=1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            old_probs = F.softmax(outputs, dim=1)\n",
    "            old_select = - F.log_softmax(outputs, dim=1).gather(1, targets.unsqueeze(1)).squeeze(1)\n",
    "            old_entropy = torch.sum(old_probs * torch.log(old_probs), dim=1)\n",
    "\n",
    "        pre_probs = F.softmax(pre_outputs, dim=1)\n",
    "        pre_select = - F.log_softmax(pre_outputs, dim=1).gather(1, targets.unsqueeze(1)).squeeze(1)\n",
    "        pre_entropy = torch.sum(pre_probs * torch.log(pre_probs), dim=1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            old_pre_probs = F.softmax(pre_outputs, dim=1)\n",
    "            old_pre_select = - F.log_softmax(pre_outputs, dim=1).gather(1, targets.unsqueeze(1)).squeeze(1)\n",
    "            old_pre_entropy = torch.sum(old_pre_probs * torch.log(old_pre_probs), dim=1)\n",
    "        \n",
    "        ref_probs = F.softmax(ref_outputs, dim=1)\n",
    "        ref_select = - F.log_softmax(ref_outputs, dim=1).gather(1, targets.unsqueeze(1)).squeeze(1)\n",
    "        ref_entropy = torch.sum(ref_probs * torch.log(ref_probs), dim=1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            old_ref_probs = F.softmax(ref_outputs, dim=1)\n",
    "            old_ref_select = - F.log_softmax(ref_outputs, dim=1).gather(1, targets.unsqueeze(1)).squeeze(1)\n",
    "            old_ref_entropy = torch.sum(old_ref_probs * torch.log(old_ref_probs), dim=1)\n",
    "\n",
    "        rewards, correct = self.compute_reconstruct_reward(outputs, targets)\n",
    "        p_rewards, _ = self.compute_positive_reward(outputs, targets)\n",
    "        n_rewards, _ = self.compute_negative_reward(outputs, targets)\n",
    "\n",
    "        ce_loss = F.cross_entropy(outputs, targets)\n",
    "\n",
    "        select_delta = (select - old_select)\n",
    "        pre_select_delta = (pre_select - old_pre_select)\n",
    "        ref_select_delta = (ref_select - old_ref_select)\n",
    "\n",
    "        entropy_delta = (entropy - old_entropy)\n",
    "        pre_entropy_delta = (pre_entropy - old_pre_entropy)\n",
    "        ref_entropy_delta = (ref_entropy - old_ref_entropy)\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            metrics = {\n",
    "                'ce_loss': ce_loss.item(),\n",
    "                'targets': select.sum().item(),\n",
    "                'entropy': entropy.sum().item(),\n",
    "            }\n",
    "    \n",
    "        return select_delta, pre_select_delta, ref_select_delta, entropy_delta, pre_entropy_delta, ref_entropy_delta, correct, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    net: torch.nn.Module,\n",
    "    get_cifar10_loaders,\n",
    "    evaluate_model,\n",
    "    batch_size: int = 64,\n",
    "    epochs: int = 300,\n",
    "    eval_interval: int = 10,\n",
    "    lr: float = 1e-3,\n",
    "    checkpoint_path: str = \"Reasoning_32R_512C_RL.pth\",\n",
    "):\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net = net.to(device)\n",
    "    ref_net = copy.deepcopy(net).to(device)\n",
    "    pre_net = copy.deepcopy(net).to(device)\n",
    "    \n",
    "    ref_count = 32\n",
    "    \n",
    "    select_embeddings1 = nn.Parameter(torch.randn(ref_count, 1, device=device))\n",
    "    select_embeddings2 = nn.Parameter(torch.randn(ref_count, 1, device=device))\n",
    "\n",
    "    entropy_embeddings1 = nn.Parameter(torch.randn(ref_count, 1, device=device))\n",
    "    entropy_embeddings2 = nn.Parameter(torch.randn(ref_count, 1, device=device))\n",
    "    \n",
    "    trainloader, testloader = get_cifar10_loaders(\n",
    "        batch_size=batch_size,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True,\n",
    "    )\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    all_params = list(net.parameters()) + [\n",
    "        select_embeddings1, select_embeddings2,\n",
    "        entropy_embeddings1, entropy_embeddings2,\n",
    "    ]\n",
    "    optimizer = torch.optim.Adam(all_params, lr=lr)\n",
    "    scaler = torch.amp.GradScaler(enabled=device.type == \"cuda\")\n",
    "    best_test_acc = 0.0\n",
    "    rl_accuracy = 0.0\n",
    "    \n",
    "    rl_trainer = RL_fine_tune(device)\n",
    "    rl_metrics_accumulator = {}\n",
    "    prev_ref = []\n",
    "    d = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        batch_count = 0\n",
    "        running_cor = 0.0\n",
    "            \n",
    "        if (epoch == 0):\n",
    "            print(\"\\nðŸ’« starting supervised training and RL fine-tuning with 1e-3 learning rate\\n\")\n",
    "\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            \n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                optimizer, T_max=300, eta_min=1e-6\n",
    "            )\n",
    "        \n",
    "        rl_metrics_accumulator = {\n",
    "            'ce_loss': 0.0, 'targets': 0.0, 'entropy': 0.0,\n",
    "            'rewards_mean': 0.0, 'rewards_std': 0.0, \n",
    "        }\n",
    "        \n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            with torch.amp.autocast(device_type=\"cuda\"):\n",
    "                outputs = net(inputs)\n",
    "                ref_outputs = ref_net(inputs)\n",
    "                pre_outputs = pre_net(inputs)\n",
    "                \n",
    "                select_delta, pre_select_delta, ref_select_delta, entropy_delta, pre_entropy_delta, ref_entropy_delta, cor, metrics = rl_trainer.emergency_policy_loss(ref_outputs, pre_outputs, outputs, targets)\n",
    "\n",
    "                select_delta = F.sigmoid(select_delta) - 2 * F.sigmoid(select_embeddings1[d % ref_count]) * F.sigmoid(pre_select_delta)\n",
    "                select_delta = F.tanh(select_delta)\n",
    "                select_delta = select_delta - 2 * F.sigmoid(select_embeddings2[d % ref_count]) * F.sigmoid(ref_select_delta)\n",
    "                \n",
    "                select_loss = select_delta.sum()\n",
    "                \n",
    "                entropy_delta = F.sigmoid(entropy_delta) - 2 * F.sigmoid(entropy_embeddings1[d % ref_count]) * F.sigmoid(pre_entropy_delta)\n",
    "                entropy_delta = F.tanh(entropy_delta)           \n",
    "                entropy_delta = entropy_delta - 2 * F.sigmoid(entropy_embeddings2[d % ref_count]) * F.sigmoid(ref_entropy_delta)  \n",
    "\n",
    "                entropy_loss = entropy_delta.sum()\n",
    "                \n",
    "                loss = select_loss + entropy_loss\n",
    "                    \n",
    "                for key, value in metrics.items():\n",
    "                    rl_metrics_accumulator[key] += value\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=0.5)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            running_cor += cor\n",
    "            batch_count += inputs.shape[0]\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "        avg_acc = running_cor / batch_count\n",
    "        avg_metrics = {k: v / batch_count for k, v in rl_metrics_accumulator.items()}\n",
    "            \n",
    "        print(f\"Epoch [{epoch + 1}] ðŸ“Š acc: {avg_acc:.3f} | Targets: {avg_metrics['targets']:.4f} | Entropy: {avg_metrics['entropy']:.4f}\")\n",
    "\n",
    "        if running_cor > rl_accuracy:\n",
    "            rl_accuracy = running_cor\n",
    "            ref = copy.deepcopy(net).to(device)\n",
    "            if d % 2 == 0:\n",
    "                prev_ref.append(ref)\n",
    "                prev_ref = prev_ref[-ref_count:]\n",
    "            ref_net = prev_ref[((d % ref_count + 1) - ((d % ref_count + 1) & -(d % ref_count + 1))) // 2]\n",
    "            pre_net = prev_ref[-1]\n",
    "            d += 1\n",
    "            print(f\"New ref model saved\")\n",
    "            \n",
    "        if (epoch + 1) % eval_interval == 0 or epoch == epochs - 1:\n",
    "            print(f\"\\nEvaluating at epoch {epoch + 1} â€¦\")\n",
    "            train_acc = evaluate_model(net, trainloader, criterion, \"Train\", device)\n",
    "            test_acc  = evaluate_model(net, testloader,  criterion, \"Test\",  device)\n",
    "            print(f\"Total Trainable Parameters: {count_parameters(net):,}\\n\")\n",
    "            print(f\"Current learning rate: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "            \n",
    "            if test_acc > best_test_acc:\n",
    "                best_test_acc = test_acc\n",
    "                torch.save(net.state_dict(), checkpoint_path)\n",
    "                print(f\"New best model saved with test accuracy: {test_acc:.2f}%\")\n",
    "    \n",
    "    print(\"Finished Training\")\n",
    "    print(f\"Best test accuracy achieved: {best_test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    net: torch.nn.Module,\n",
    "    dataloader,\n",
    "    criterion,\n",
    "    dataset_name: str = \"\",\n",
    "    device=None,\n",
    "):\n",
    "    device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    was_training = net.training\n",
    "    net.eval()\n",
    "\n",
    "    total_correct = 0\n",
    "    total_seen = 0\n",
    "    loss_sum = 0.0\n",
    "\n",
    "    use_bf16 = torch.cuda.is_available() and torch.cuda.is_bf16_supported()\n",
    "    autocast_ctx = (torch.amp.autocast(device_type=\"cuda\", dtype=torch.bfloat16)\n",
    "                    if use_bf16 else contextlib.nullcontext())\n",
    "\n",
    "    with torch.no_grad(), autocast_ctx:\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            outputs = net(images)  \n",
    "            batch_loss = criterion(outputs.float(), labels)\n",
    "\n",
    "            if not torch.isfinite(batch_loss):\n",
    "                print(\"[eval/warn] non-finite loss\",\n",
    "                      \"logits_minmax=\", float(outputs.min()), float(outputs.max()))\n",
    "                continue\n",
    "\n",
    "            bs = labels.size(0)\n",
    "            loss_sum    += batch_loss.item() * bs\n",
    "            total_seen  += bs\n",
    "\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            total_correct += (preds == labels).sum().item()\n",
    "\n",
    "    if total_seen == 0:\n",
    "        avg_loss = float(\"nan\")\n",
    "        acc = 0.0\n",
    "    else:\n",
    "        avg_loss = loss_sum / total_seen\n",
    "        acc = 100.0 * total_correct / total_seen\n",
    "\n",
    "    print(f\"{dataset_name} Accuracy: {acc:.2f}%\")\n",
    "    print(f\"{dataset_name} Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    if was_training:\n",
    "        net.train()\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Trainable Parameters: 515,754\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Example usage:\n",
    "model = Net()\n",
    "print(f\"Total Trainable Parameters: {count_parameters(model):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’« starting supervised training and RL fine-tuning with 1e-3 learning rate\n",
      "\n",
      "Epoch [1] ðŸ“Š acc: 0.326 | Targets: 1.9810 | Entropy: -2.1645\n",
      "New ref model saved\n",
      "Epoch [2] ðŸ“Š acc: 0.481 | Targets: 1.6776 | Entropy: -2.0692\n",
      "New ref model saved\n",
      "Epoch [3] ðŸ“Š acc: 0.560 | Targets: 1.5545 | Entropy: -2.0368\n",
      "New ref model saved\n",
      "Epoch [4] ðŸ“Š acc: 0.610 | Targets: 1.4480 | Entropy: -1.9864\n",
      "New ref model saved\n",
      "Epoch [5] ðŸ“Š acc: 0.649 | Targets: 1.3918 | Entropy: -1.9780\n",
      "New ref model saved\n",
      "Epoch [6] ðŸ“Š acc: 0.669 | Targets: 1.3242 | Entropy: -1.9363\n",
      "New ref model saved\n",
      "Epoch [7] ðŸ“Š acc: 0.695 | Targets: 1.2781 | Entropy: -1.9209\n",
      "New ref model saved\n",
      "Epoch [8] ðŸ“Š acc: 0.713 | Targets: 1.2866 | Entropy: -1.9588\n",
      "New ref model saved\n",
      "Epoch [9] ðŸ“Š acc: 0.725 | Targets: 1.2960 | Entropy: -1.9865\n",
      "New ref model saved\n",
      "Epoch [10] ðŸ“Š acc: 0.733 | Targets: 1.2631 | Entropy: -1.9650\n",
      "New ref model saved\n",
      "\n",
      "Evaluating at epoch 10 â€¦\n",
      "Train Accuracy: 75.66%\n",
      "Train Average Loss: 1.2600\n",
      "Test Accuracy: 80.04%\n",
      "Test Average Loss: 1.1855\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 9.97e-04\n",
      "New best model saved with test accuracy: 80.04%\n",
      "Epoch [11] ðŸ“Š acc: 0.745 | Targets: 1.2482 | Entropy: -1.9656\n",
      "New ref model saved\n",
      "Epoch [12] ðŸ“Š acc: 0.752 | Targets: 1.2098 | Entropy: -1.9388\n",
      "New ref model saved\n",
      "Epoch [13] ðŸ“Š acc: 0.757 | Targets: 1.1749 | Entropy: -1.9102\n",
      "New ref model saved\n",
      "Epoch [14] ðŸ“Š acc: 0.765 | Targets: 1.2190 | Entropy: -1.9696\n",
      "New ref model saved\n",
      "Epoch [15] ðŸ“Š acc: 0.770 | Targets: 1.2197 | Entropy: -1.9789\n",
      "New ref model saved\n",
      "Epoch [16] ðŸ“Š acc: 0.775 | Targets: 1.2006 | Entropy: -1.9661\n",
      "New ref model saved\n",
      "Epoch [17] ðŸ“Š acc: 0.778 | Targets: 1.1268 | Entropy: -1.8938\n",
      "New ref model saved\n",
      "Epoch [18] ðŸ“Š acc: 0.784 | Targets: 1.1407 | Entropy: -1.9204\n",
      "New ref model saved\n",
      "Epoch [19] ðŸ“Š acc: 0.789 | Targets: 1.1015 | Entropy: -1.8823\n",
      "New ref model saved\n",
      "Epoch [20] ðŸ“Š acc: 0.794 | Targets: 1.1211 | Entropy: -1.9129\n",
      "New ref model saved\n",
      "\n",
      "Evaluating at epoch 20 â€¦\n",
      "Train Accuracy: 80.69%\n",
      "Train Average Loss: 1.0676\n",
      "Test Accuracy: 85.31%\n",
      "Test Average Loss: 0.9910\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 9.89e-04\n",
      "New best model saved with test accuracy: 85.31%\n",
      "Epoch [21] ðŸ“Š acc: 0.799 | Targets: 1.2007 | Entropy: -1.9976\n",
      "New ref model saved\n",
      "Epoch [22] ðŸ“Š acc: 0.800 | Targets: 1.1366 | Entropy: -1.9390\n",
      "New ref model saved\n",
      "Epoch [23] ðŸ“Š acc: 0.804 | Targets: 1.1116 | Entropy: -1.9203\n",
      "New ref model saved\n",
      "Epoch [24] ðŸ“Š acc: 0.806 | Targets: 1.1064 | Entropy: -1.9187\n",
      "New ref model saved\n",
      "Epoch [25] ðŸ“Š acc: 0.810 | Targets: 1.0851 | Entropy: -1.9028\n",
      "New ref model saved\n",
      "Epoch [26] ðŸ“Š acc: 0.814 | Targets: 1.0438 | Entropy: -1.8621\n",
      "New ref model saved\n",
      "Epoch [27] ðŸ“Š acc: 0.816 | Targets: 1.0889 | Entropy: -1.9132\n",
      "New ref model saved\n",
      "Epoch [28] ðŸ“Š acc: 0.821 | Targets: 1.0982 | Entropy: -1.9295\n",
      "New ref model saved\n",
      "Epoch [29] ðŸ“Š acc: 0.820 | Targets: 1.1039 | Entropy: -1.9371\n",
      "Epoch [30] ðŸ“Š acc: 0.822 | Targets: 1.1192 | Entropy: -1.9573\n",
      "New ref model saved\n",
      "\n",
      "Evaluating at epoch 30 â€¦\n",
      "Train Accuracy: 82.98%\n",
      "Train Average Loss: 1.1063\n",
      "Test Accuracy: 86.18%\n",
      "Test Average Loss: 1.0268\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 9.76e-04\n",
      "New best model saved with test accuracy: 86.18%\n",
      "Epoch [31] ðŸ“Š acc: 0.822 | Targets: 1.0534 | Entropy: -1.8885\n",
      "Epoch [32] ðŸ“Š acc: 0.825 | Targets: 1.0220 | Entropy: -1.8588\n",
      "New ref model saved\n",
      "Epoch [33] ðŸ“Š acc: 0.830 | Targets: 1.0422 | Entropy: -1.8893\n",
      "New ref model saved\n",
      "Epoch [34] ðŸ“Š acc: 0.835 | Targets: 1.0848 | Entropy: -1.9394\n",
      "New ref model saved\n",
      "Epoch [35] ðŸ“Š acc: 0.834 | Targets: 1.1343 | Entropy: -1.9850\n",
      "Epoch [36] ðŸ“Š acc: 0.834 | Targets: 1.1176 | Entropy: -1.9710\n",
      "Epoch [37] ðŸ“Š acc: 0.836 | Targets: 1.0935 | Entropy: -1.9526\n",
      "New ref model saved\n",
      "Epoch [38] ðŸ“Š acc: 0.836 | Targets: 1.0204 | Entropy: -1.8770\n",
      "Epoch [39] ðŸ“Š acc: 0.838 | Targets: 1.0273 | Entropy: -1.8895\n",
      "New ref model saved\n",
      "Epoch [40] ðŸ“Š acc: 0.841 | Targets: 1.0421 | Entropy: -1.9088\n",
      "New ref model saved\n",
      "\n",
      "Evaluating at epoch 40 â€¦\n",
      "Train Accuracy: 84.00%\n",
      "Train Average Loss: 1.0394\n",
      "Test Accuracy: 87.57%\n",
      "Test Average Loss: 0.9654\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 9.57e-04\n",
      "New best model saved with test accuracy: 87.57%\n",
      "Epoch [41] ðŸ“Š acc: 0.841 | Targets: 1.0206 | Entropy: -1.8870\n",
      "New ref model saved\n",
      "Epoch [42] ðŸ“Š acc: 0.844 | Targets: 1.0236 | Entropy: -1.8938\n",
      "New ref model saved\n",
      "Epoch [43] ðŸ“Š acc: 0.844 | Targets: 0.9748 | Entropy: -1.8392\n",
      "Epoch [44] ðŸ“Š acc: 0.848 | Targets: 0.9915 | Entropy: -1.8647\n",
      "New ref model saved\n",
      "Epoch [45] ðŸ“Š acc: 0.850 | Targets: 0.9993 | Entropy: -1.8769\n",
      "New ref model saved\n",
      "Epoch [46] ðŸ“Š acc: 0.851 | Targets: 1.0059 | Entropy: -1.8870\n",
      "New ref model saved\n",
      "Epoch [47] ðŸ“Š acc: 0.852 | Targets: 1.0432 | Entropy: -1.9268\n",
      "New ref model saved\n",
      "Epoch [48] ðŸ“Š acc: 0.851 | Targets: 1.0549 | Entropy: -1.9374\n",
      "Epoch [49] ðŸ“Š acc: 0.853 | Targets: 1.0423 | Entropy: -1.9267\n",
      "New ref model saved\n",
      "Epoch [50] ðŸ“Š acc: 0.856 | Targets: 1.0275 | Entropy: -1.9164\n",
      "New ref model saved\n",
      "\n",
      "Evaluating at epoch 50 â€¦\n",
      "Train Accuracy: 86.27%\n",
      "Train Average Loss: 0.9959\n",
      "Test Accuracy: 88.92%\n",
      "Test Average Loss: 0.9242\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 9.33e-04\n",
      "New best model saved with test accuracy: 88.92%\n",
      "Epoch [51] ðŸ“Š acc: 0.852 | Targets: 1.0050 | Entropy: -1.8912\n",
      "Epoch [52] ðŸ“Š acc: 0.857 | Targets: 1.0035 | Entropy: -1.8950\n",
      "New ref model saved\n",
      "Epoch [53] ðŸ“Š acc: 0.857 | Targets: 0.9883 | Entropy: -1.8807\n",
      "New ref model saved\n",
      "Epoch [54] ðŸ“Š acc: 0.859 | Targets: 1.0284 | Entropy: -1.9218\n",
      "New ref model saved\n",
      "Epoch [55] ðŸ“Š acc: 0.861 | Targets: 1.0259 | Entropy: -1.9237\n",
      "New ref model saved\n",
      "Epoch [56] ðŸ“Š acc: 0.862 | Targets: 1.0168 | Entropy: -1.9156\n",
      "New ref model saved\n",
      "Epoch [57] ðŸ“Š acc: 0.862 | Targets: 0.9680 | Entropy: -1.8649\n",
      "New ref model saved\n",
      "Epoch [58] ðŸ“Š acc: 0.862 | Targets: 0.9849 | Entropy: -1.8861\n",
      "Epoch [59] ðŸ“Š acc: 0.866 | Targets: 0.9877 | Entropy: -1.8913\n",
      "New ref model saved\n",
      "Epoch [60] ðŸ“Š acc: 0.865 | Targets: 0.9500 | Entropy: -1.8510\n",
      "\n",
      "Evaluating at epoch 60 â€¦\n",
      "Train Accuracy: 86.36%\n",
      "Train Average Loss: 0.9490\n",
      "Test Accuracy: 89.11%\n",
      "Test Average Loss: 0.8879\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 9.05e-04\n",
      "New best model saved with test accuracy: 89.11%\n",
      "Epoch [61] ðŸ“Š acc: 0.865 | Targets: 0.9673 | Entropy: -1.8716\n",
      "Epoch [62] ðŸ“Š acc: 0.869 | Targets: 0.9696 | Entropy: -1.8798\n",
      "New ref model saved\n",
      "Epoch [63] ðŸ“Š acc: 0.868 | Targets: 0.9339 | Entropy: -1.8393\n",
      "Epoch [64] ðŸ“Š acc: 0.871 | Targets: 0.9496 | Entropy: -1.8594\n",
      "New ref model saved\n",
      "Epoch [65] ðŸ“Š acc: 0.873 | Targets: 1.0254 | Entropy: -1.9384\n",
      "New ref model saved\n",
      "Epoch [66] ðŸ“Š acc: 0.872 | Targets: 0.9897 | Entropy: -1.9050\n",
      "Epoch [67] ðŸ“Š acc: 0.873 | Targets: 0.9877 | Entropy: -1.9022\n",
      "New ref model saved\n",
      "Epoch [68] ðŸ“Š acc: 0.872 | Targets: 0.9775 | Entropy: -1.8933\n",
      "Epoch [69] ðŸ“Š acc: 0.876 | Targets: 0.9758 | Entropy: -1.8952\n",
      "New ref model saved\n",
      "Epoch [70] ðŸ“Š acc: 0.875 | Targets: 0.9638 | Entropy: -1.8831\n",
      "\n",
      "Evaluating at epoch 70 â€¦\n",
      "Train Accuracy: 87.53%\n",
      "Train Average Loss: 0.9609\n",
      "Test Accuracy: 89.85%\n",
      "Test Average Loss: 0.9057\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 8.72e-04\n",
      "New best model saved with test accuracy: 89.85%\n",
      "Epoch [71] ðŸ“Š acc: 0.876 | Targets: 0.9665 | Entropy: -1.8877\n",
      "New ref model saved\n",
      "Epoch [72] ðŸ“Š acc: 0.878 | Targets: 0.9588 | Entropy: -1.8801\n",
      "New ref model saved\n",
      "Epoch [73] ðŸ“Š acc: 0.876 | Targets: 0.9366 | Entropy: -1.8565\n",
      "Epoch [74] ðŸ“Š acc: 0.879 | Targets: 0.9483 | Entropy: -1.8726\n",
      "New ref model saved\n",
      "Epoch [75] ðŸ“Š acc: 0.882 | Targets: 0.9604 | Entropy: -1.8884\n",
      "New ref model saved\n",
      "Epoch [76] ðŸ“Š acc: 0.881 | Targets: 0.9782 | Entropy: -1.9058\n",
      "Epoch [77] ðŸ“Š acc: 0.882 | Targets: 0.9715 | Entropy: -1.9015\n",
      "New ref model saved\n",
      "Epoch [78] ðŸ“Š acc: 0.882 | Targets: 0.9910 | Entropy: -1.9202\n",
      "Epoch [79] ðŸ“Š acc: 0.883 | Targets: 0.9809 | Entropy: -1.9102\n",
      "New ref model saved\n",
      "Epoch [80] ðŸ“Š acc: 0.883 | Targets: 0.9320 | Entropy: -1.8609\n",
      "\n",
      "Evaluating at epoch 80 â€¦\n",
      "Train Accuracy: 88.07%\n",
      "Train Average Loss: 0.9454\n",
      "Test Accuracy: 90.41%\n",
      "Test Average Loss: 0.8896\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 8.35e-04\n",
      "New best model saved with test accuracy: 90.41%\n",
      "Epoch [81] ðŸ“Š acc: 0.885 | Targets: 0.9427 | Entropy: -1.8750\n",
      "New ref model saved\n",
      "Epoch [82] ðŸ“Š acc: 0.886 | Targets: 0.9455 | Entropy: -1.8799\n",
      "New ref model saved\n",
      "Epoch [83] ðŸ“Š acc: 0.885 | Targets: 0.9835 | Entropy: -1.9176\n",
      "Epoch [84] ðŸ“Š acc: 0.888 | Targets: 0.9705 | Entropy: -1.9080\n",
      "New ref model saved\n",
      "Epoch [85] ðŸ“Š acc: 0.886 | Targets: 0.9775 | Entropy: -1.9132\n",
      "Epoch [86] ðŸ“Š acc: 0.890 | Targets: 0.9616 | Entropy: -1.9022\n",
      "New ref model saved\n",
      "Epoch [87] ðŸ“Š acc: 0.889 | Targets: 0.9436 | Entropy: -1.8830\n",
      "Epoch [88] ðŸ“Š acc: 0.890 | Targets: 0.9455 | Entropy: -1.8867\n",
      "New ref model saved\n",
      "Epoch [89] ðŸ“Š acc: 0.890 | Targets: 0.9515 | Entropy: -1.8922\n",
      "Epoch [90] ðŸ“Š acc: 0.891 | Targets: 0.9487 | Entropy: -1.8919\n",
      "New ref model saved\n",
      "\n",
      "Evaluating at epoch 90 â€¦\n",
      "Train Accuracy: 88.66%\n",
      "Train Average Loss: 0.9712\n",
      "Test Accuracy: 90.26%\n",
      "Test Average Loss: 0.9316\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 7.94e-04\n",
      "Epoch [91] ðŸ“Š acc: 0.891 | Targets: 0.9407 | Entropy: -1.8829\n",
      "Epoch [92] ðŸ“Š acc: 0.892 | Targets: 0.9432 | Entropy: -1.8868\n",
      "New ref model saved\n",
      "Epoch [93] ðŸ“Š acc: 0.893 | Targets: 0.9381 | Entropy: -1.8847\n",
      "New ref model saved\n",
      "Epoch [94] ðŸ“Š acc: 0.894 | Targets: 0.9266 | Entropy: -1.8719\n",
      "New ref model saved\n",
      "Epoch [95] ðŸ“Š acc: 0.895 | Targets: 0.9323 | Entropy: -1.8794\n",
      "New ref model saved\n",
      "Epoch [96] ðŸ“Š acc: 0.896 | Targets: 0.9318 | Entropy: -1.8805\n",
      "New ref model saved\n",
      "Epoch [97] ðŸ“Š acc: 0.897 | Targets: 0.9466 | Entropy: -1.8981\n",
      "New ref model saved\n",
      "Epoch [98] ðŸ“Š acc: 0.896 | Targets: 0.9509 | Entropy: -1.8999\n",
      "Epoch [99] ðŸ“Š acc: 0.897 | Targets: 0.9440 | Entropy: -1.8957\n",
      "Epoch [100] ðŸ“Š acc: 0.896 | Targets: 0.9407 | Entropy: -1.8929\n",
      "\n",
      "Evaluating at epoch 100 â€¦\n",
      "Train Accuracy: 89.88%\n",
      "Train Average Loss: 0.9443\n",
      "Test Accuracy: 91.28%\n",
      "Test Average Loss: 0.9080\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 7.50e-04\n",
      "New best model saved with test accuracy: 91.28%\n",
      "Epoch [101] ðŸ“Š acc: 0.898 | Targets: 0.9381 | Entropy: -1.8922\n",
      "New ref model saved\n",
      "Epoch [102] ðŸ“Š acc: 0.898 | Targets: 0.9403 | Entropy: -1.8936\n",
      "Epoch [103] ðŸ“Š acc: 0.899 | Targets: 0.9363 | Entropy: -1.8913\n",
      "New ref model saved\n",
      "Epoch [104] ðŸ“Š acc: 0.902 | Targets: 0.9251 | Entropy: -1.8830\n",
      "New ref model saved\n",
      "Epoch [105] ðŸ“Š acc: 0.901 | Targets: 0.9207 | Entropy: -1.8779\n",
      "Epoch [106] ðŸ“Š acc: 0.902 | Targets: 0.9256 | Entropy: -1.8830\n",
      "Epoch [107] ðŸ“Š acc: 0.902 | Targets: 0.9237 | Entropy: -1.8836\n",
      "Epoch [108] ðŸ“Š acc: 0.903 | Targets: 0.9259 | Entropy: -1.8855\n",
      "New ref model saved\n",
      "Epoch [109] ðŸ“Š acc: 0.904 | Targets: 0.9324 | Entropy: -1.8939\n",
      "New ref model saved\n",
      "Epoch [110] ðŸ“Š acc: 0.905 | Targets: 0.9308 | Entropy: -1.8947\n",
      "New ref model saved\n",
      "\n",
      "Evaluating at epoch 110 â€¦\n",
      "Train Accuracy: 89.91%\n",
      "Train Average Loss: 0.9330\n",
      "Test Accuracy: 91.24%\n",
      "Test Average Loss: 0.8968\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 7.04e-04\n",
      "Epoch [111] ðŸ“Š acc: 0.902 | Targets: 0.9325 | Entropy: -1.8924\n",
      "Epoch [112] ðŸ“Š acc: 0.904 | Targets: 0.9282 | Entropy: -1.8900\n",
      "Epoch [113] ðŸ“Š acc: 0.904 | Targets: 0.9243 | Entropy: -1.8881\n",
      "Epoch [114] ðŸ“Š acc: 0.906 | Targets: 0.9234 | Entropy: -1.8878\n",
      "New ref model saved\n",
      "Epoch [115] ðŸ“Š acc: 0.907 | Targets: 0.9027 | Entropy: -1.8684\n",
      "New ref model saved\n",
      "Epoch [116] ðŸ“Š acc: 0.909 | Targets: 0.9140 | Entropy: -1.8805\n",
      "New ref model saved\n",
      "Epoch [117] ðŸ“Š acc: 0.908 | Targets: 0.9082 | Entropy: -1.8765\n",
      "Epoch [118] ðŸ“Š acc: 0.908 | Targets: 0.9138 | Entropy: -1.8804\n",
      "Epoch [119] ðŸ“Š acc: 0.910 | Targets: 0.9107 | Entropy: -1.8810\n",
      "New ref model saved\n",
      "Epoch [120] ðŸ“Š acc: 0.910 | Targets: 0.8926 | Entropy: -1.8628\n",
      "\n",
      "Evaluating at epoch 120 â€¦\n",
      "Train Accuracy: 90.83%\n",
      "Train Average Loss: 0.8971\n",
      "Test Accuracy: 91.91%\n",
      "Test Average Loss: 0.8682\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 6.55e-04\n",
      "New best model saved with test accuracy: 91.91%\n",
      "Epoch [121] ðŸ“Š acc: 0.908 | Targets: 0.9037 | Entropy: -1.8724\n",
      "Epoch [122] ðŸ“Š acc: 0.907 | Targets: 0.9095 | Entropy: -1.8771\n",
      "Epoch [123] ðŸ“Š acc: 0.912 | Targets: 0.9067 | Entropy: -1.8777\n",
      "New ref model saved\n",
      "Epoch [124] ðŸ“Š acc: 0.914 | Targets: 0.9243 | Entropy: -1.9002\n",
      "New ref model saved\n",
      "Epoch [125] ðŸ“Š acc: 0.911 | Targets: 0.9109 | Entropy: -1.8849\n",
      "Epoch [126] ðŸ“Š acc: 0.913 | Targets: 0.9096 | Entropy: -1.8841\n",
      "Epoch [127] ðŸ“Š acc: 0.914 | Targets: 0.9069 | Entropy: -1.8836\n",
      "Epoch [128] ðŸ“Š acc: 0.913 | Targets: 0.9088 | Entropy: -1.8836\n",
      "Epoch [129] ðŸ“Š acc: 0.914 | Targets: 0.9088 | Entropy: -1.8842\n",
      "Epoch [130] ðŸ“Š acc: 0.915 | Targets: 0.9052 | Entropy: -1.8826\n",
      "New ref model saved\n",
      "\n",
      "Evaluating at epoch 130 â€¦\n",
      "Train Accuracy: 91.53%\n",
      "Train Average Loss: 0.8980\n",
      "Test Accuracy: 92.19%\n",
      "Test Average Loss: 0.8773\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 6.04e-04\n",
      "New best model saved with test accuracy: 92.19%\n",
      "Epoch [131] ðŸ“Š acc: 0.916 | Targets: 0.9014 | Entropy: -1.8802\n",
      "New ref model saved\n",
      "Epoch [132] ðŸ“Š acc: 0.917 | Targets: 0.8960 | Entropy: -1.8761\n",
      "New ref model saved\n",
      "Epoch [133] ðŸ“Š acc: 0.916 | Targets: 0.8958 | Entropy: -1.8743\n",
      "Epoch [134] ðŸ“Š acc: 0.915 | Targets: 0.8969 | Entropy: -1.8762\n",
      "Epoch [135] ðŸ“Š acc: 0.917 | Targets: 0.8968 | Entropy: -1.8780\n",
      "New ref model saved\n",
      "Epoch [136] ðŸ“Š acc: 0.918 | Targets: 0.8868 | Entropy: -1.8688\n",
      "New ref model saved\n",
      "Epoch [137] ðŸ“Š acc: 0.916 | Targets: 0.8987 | Entropy: -1.8781\n",
      "Epoch [138] ðŸ“Š acc: 0.918 | Targets: 0.8966 | Entropy: -1.8790\n",
      "Epoch [139] ðŸ“Š acc: 0.918 | Targets: 0.8969 | Entropy: -1.8791\n",
      "Epoch [140] ðŸ“Š acc: 0.918 | Targets: 0.8966 | Entropy: -1.8797\n",
      "\n",
      "Evaluating at epoch 140 â€¦\n",
      "Train Accuracy: 92.28%\n",
      "Train Average Loss: 0.8823\n",
      "Test Accuracy: 92.80%\n",
      "Test Average Loss: 0.8609\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 5.53e-04\n",
      "New best model saved with test accuracy: 92.80%\n",
      "Epoch [141] ðŸ“Š acc: 0.917 | Targets: 0.8976 | Entropy: -1.8799\n",
      "Epoch [142] ðŸ“Š acc: 0.921 | Targets: 0.8951 | Entropy: -1.8799\n",
      "New ref model saved\n",
      "Epoch [143] ðŸ“Š acc: 0.919 | Targets: 0.8990 | Entropy: -1.8840\n",
      "Epoch [144] ðŸ“Š acc: 0.920 | Targets: 0.8969 | Entropy: -1.8823\n",
      "Epoch [145] ðŸ“Š acc: 0.922 | Targets: 0.8925 | Entropy: -1.8809\n",
      "New ref model saved\n",
      "Epoch [146] ðŸ“Š acc: 0.922 | Targets: 0.8977 | Entropy: -1.8864\n",
      "Epoch [147] ðŸ“Š acc: 0.920 | Targets: 0.8995 | Entropy: -1.8853\n",
      "Epoch [148] ðŸ“Š acc: 0.922 | Targets: 0.8930 | Entropy: -1.8827\n",
      "New ref model saved\n",
      "Epoch [149] ðŸ“Š acc: 0.923 | Targets: 0.8786 | Entropy: -1.8684\n",
      "New ref model saved\n",
      "Epoch [150] ðŸ“Š acc: 0.925 | Targets: 0.8810 | Entropy: -1.8714\n",
      "New ref model saved\n",
      "\n",
      "Evaluating at epoch 150 â€¦\n",
      "Train Accuracy: 92.45%\n",
      "Train Average Loss: 0.8804\n",
      "Test Accuracy: 92.80%\n",
      "Test Average Loss: 0.8626\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 5.01e-04\n",
      "Epoch [151] ðŸ“Š acc: 0.925 | Targets: 0.8951 | Entropy: -1.8864\n",
      "New ref model saved\n",
      "Epoch [152] ðŸ“Š acc: 0.924 | Targets: 0.8938 | Entropy: -1.8839\n",
      "Epoch [153] ðŸ“Š acc: 0.925 | Targets: 0.8878 | Entropy: -1.8810\n",
      "New ref model saved\n",
      "Epoch [154] ðŸ“Š acc: 0.924 | Targets: 0.8845 | Entropy: -1.8756\n",
      "Epoch [155] ðŸ“Š acc: 0.926 | Targets: 0.8824 | Entropy: -1.8761\n",
      "New ref model saved\n",
      "Epoch [156] ðŸ“Š acc: 0.928 | Targets: 0.8825 | Entropy: -1.8771\n",
      "New ref model saved\n",
      "Epoch [157] ðŸ“Š acc: 0.926 | Targets: 0.8799 | Entropy: -1.8742\n",
      "Epoch [158] ðŸ“Š acc: 0.926 | Targets: 0.8816 | Entropy: -1.8760\n",
      "Epoch [159] ðŸ“Š acc: 0.927 | Targets: 0.8815 | Entropy: -1.8763\n",
      "Epoch [160] ðŸ“Š acc: 0.928 | Targets: 0.8814 | Entropy: -1.8766\n",
      "New ref model saved\n",
      "\n",
      "Evaluating at epoch 160 â€¦\n",
      "Train Accuracy: 93.15%\n",
      "Train Average Loss: 0.8802\n",
      "Test Accuracy: 93.17%\n",
      "Test Average Loss: 0.8696\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 4.48e-04\n",
      "New best model saved with test accuracy: 93.17%\n",
      "Epoch [161] ðŸ“Š acc: 0.929 | Targets: 0.8762 | Entropy: -1.8732\n",
      "New ref model saved\n",
      "Epoch [162] ðŸ“Š acc: 0.927 | Targets: 0.8726 | Entropy: -1.8680\n",
      "Epoch [163] ðŸ“Š acc: 0.928 | Targets: 0.8720 | Entropy: -1.8702\n",
      "Epoch [164] ðŸ“Š acc: 0.930 | Targets: 0.8715 | Entropy: -1.8714\n",
      "New ref model saved\n",
      "Epoch [165] ðŸ“Š acc: 0.930 | Targets: 0.8713 | Entropy: -1.8707\n",
      "New ref model saved\n",
      "Epoch [166] ðŸ“Š acc: 0.928 | Targets: 0.8741 | Entropy: -1.8717\n",
      "Epoch [167] ðŸ“Š acc: 0.930 | Targets: 0.8716 | Entropy: -1.8724\n",
      "Epoch [168] ðŸ“Š acc: 0.930 | Targets: 0.8717 | Entropy: -1.8730\n",
      "Epoch [169] ðŸ“Š acc: 0.931 | Targets: 0.8712 | Entropy: -1.8730\n",
      "New ref model saved\n",
      "Epoch [170] ðŸ“Š acc: 0.931 | Targets: 0.8784 | Entropy: -1.8793\n",
      "\n",
      "Evaluating at epoch 170 â€¦\n",
      "Train Accuracy: 93.35%\n",
      "Train Average Loss: 0.8747\n",
      "Test Accuracy: 93.14%\n",
      "Test Average Loss: 0.8676\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 3.97e-04\n",
      "Epoch [171] ðŸ“Š acc: 0.932 | Targets: 0.8758 | Entropy: -1.8782\n",
      "New ref model saved\n",
      "Epoch [172] ðŸ“Š acc: 0.934 | Targets: 0.8710 | Entropy: -1.8757\n",
      "New ref model saved\n",
      "Epoch [173] ðŸ“Š acc: 0.932 | Targets: 0.8733 | Entropy: -1.8765\n",
      "Epoch [174] ðŸ“Š acc: 0.933 | Targets: 0.8708 | Entropy: -1.8756\n",
      "Epoch [175] ðŸ“Š acc: 0.933 | Targets: 0.8694 | Entropy: -1.8749\n",
      "Epoch [176] ðŸ“Š acc: 0.934 | Targets: 0.8679 | Entropy: -1.8746\n",
      "New ref model saved\n",
      "Epoch [177] ðŸ“Š acc: 0.936 | Targets: 0.8633 | Entropy: -1.8709\n",
      "New ref model saved\n",
      "Epoch [178] ðŸ“Š acc: 0.934 | Targets: 0.8657 | Entropy: -1.8722\n",
      "Epoch [179] ðŸ“Š acc: 0.934 | Targets: 0.8679 | Entropy: -1.8732\n",
      "Epoch [180] ðŸ“Š acc: 0.934 | Targets: 0.8682 | Entropy: -1.8740\n",
      "\n",
      "Evaluating at epoch 180 â€¦\n",
      "Train Accuracy: 93.80%\n",
      "Train Average Loss: 0.8682\n",
      "Test Accuracy: 93.16%\n",
      "Test Average Loss: 0.8658\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 3.46e-04\n",
      "Epoch [181] ðŸ“Š acc: 0.937 | Targets: 0.8647 | Entropy: -1.8728\n",
      "New ref model saved\n",
      "Epoch [182] ðŸ“Š acc: 0.937 | Targets: 0.8658 | Entropy: -1.8762\n",
      "New ref model saved\n",
      "Epoch [183] ðŸ“Š acc: 0.936 | Targets: 0.8688 | Entropy: -1.8775\n",
      "Epoch [184] ðŸ“Š acc: 0.936 | Targets: 0.8664 | Entropy: -1.8760\n",
      "Epoch [185] ðŸ“Š acc: 0.938 | Targets: 0.8623 | Entropy: -1.8745\n",
      "New ref model saved\n",
      "Epoch [186] ðŸ“Š acc: 0.937 | Targets: 0.8639 | Entropy: -1.8737\n",
      "Epoch [187] ðŸ“Š acc: 0.938 | Targets: 0.8601 | Entropy: -1.8727\n",
      "New ref model saved\n",
      "Epoch [188] ðŸ“Š acc: 0.938 | Targets: 0.8504 | Entropy: -1.8623\n",
      "New ref model saved\n",
      "Epoch [189] ðŸ“Š acc: 0.940 | Targets: 0.8544 | Entropy: -1.8682\n",
      "New ref model saved\n",
      "Epoch [190] ðŸ“Š acc: 0.939 | Targets: 0.8571 | Entropy: -1.8697\n",
      "\n",
      "Evaluating at epoch 190 â€¦\n",
      "Train Accuracy: 93.73%\n",
      "Train Average Loss: 0.8634\n",
      "Test Accuracy: 93.10%\n",
      "Test Average Loss: 0.8658\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 2.97e-04\n",
      "Epoch [191] ðŸ“Š acc: 0.938 | Targets: 0.8580 | Entropy: -1.8705\n",
      "Epoch [192] ðŸ“Š acc: 0.939 | Targets: 0.8592 | Entropy: -1.8710\n",
      "Epoch [193] ðŸ“Š acc: 0.940 | Targets: 0.8563 | Entropy: -1.8703\n",
      "New ref model saved\n",
      "Epoch [194] ðŸ“Š acc: 0.939 | Targets: 0.8521 | Entropy: -1.8672\n",
      "Epoch [195] ðŸ“Š acc: 0.939 | Targets: 0.8552 | Entropy: -1.8684\n",
      "Epoch [196] ðŸ“Š acc: 0.940 | Targets: 0.8540 | Entropy: -1.8686\n",
      "New ref model saved\n",
      "Epoch [197] ðŸ“Š acc: 0.942 | Targets: 0.8651 | Entropy: -1.8806\n",
      "New ref model saved\n",
      "Epoch [198] ðŸ“Š acc: 0.942 | Targets: 0.8539 | Entropy: -1.8706\n",
      "New ref model saved\n",
      "Epoch [199] ðŸ“Š acc: 0.941 | Targets: 0.8549 | Entropy: -1.8704\n",
      "Epoch [200] ðŸ“Š acc: 0.941 | Targets: 0.8547 | Entropy: -1.8707\n",
      "\n",
      "Evaluating at epoch 200 â€¦\n",
      "Train Accuracy: 94.50%\n",
      "Train Average Loss: 0.8447\n",
      "Test Accuracy: 93.74%\n",
      "Test Average Loss: 0.8524\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 2.51e-04\n",
      "New best model saved with test accuracy: 93.74%\n",
      "Epoch [201] ðŸ“Š acc: 0.940 | Targets: 0.8549 | Entropy: -1.8703\n",
      "Epoch [202] ðŸ“Š acc: 0.942 | Targets: 0.8534 | Entropy: -1.8702\n",
      "Epoch [203] ðŸ“Š acc: 0.942 | Targets: 0.8515 | Entropy: -1.8696\n",
      "New ref model saved\n",
      "Epoch [204] ðŸ“Š acc: 0.944 | Targets: 0.8463 | Entropy: -1.8663\n",
      "New ref model saved\n",
      "Epoch [205] ðŸ“Š acc: 0.943 | Targets: 0.8496 | Entropy: -1.8680\n",
      "Epoch [206] ðŸ“Š acc: 0.942 | Targets: 0.8496 | Entropy: -1.8682\n",
      "Epoch [207] ðŸ“Š acc: 0.942 | Targets: 0.8502 | Entropy: -1.8685\n",
      "Epoch [208] ðŸ“Š acc: 0.944 | Targets: 0.8474 | Entropy: -1.8678\n",
      "Epoch [209] ðŸ“Š acc: 0.943 | Targets: 0.8518 | Entropy: -1.8694\n",
      "Epoch [210] ðŸ“Š acc: 0.947 | Targets: 0.8452 | Entropy: -1.8679\n",
      "New ref model saved\n",
      "\n",
      "Evaluating at epoch 210 â€¦\n",
      "Train Accuracy: 94.48%\n",
      "Train Average Loss: 0.8449\n",
      "Test Accuracy: 93.48%\n",
      "Test Average Loss: 0.8554\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 2.07e-04\n",
      "Epoch [211] ðŸ“Š acc: 0.945 | Targets: 0.8408 | Entropy: -1.8620\n",
      "Epoch [212] ðŸ“Š acc: 0.946 | Targets: 0.8424 | Entropy: -1.8636\n",
      "Epoch [213] ðŸ“Š acc: 0.945 | Targets: 0.8423 | Entropy: -1.8642\n",
      "Epoch [214] ðŸ“Š acc: 0.945 | Targets: 0.8436 | Entropy: -1.8648\n",
      "Epoch [215] ðŸ“Š acc: 0.945 | Targets: 0.8458 | Entropy: -1.8660\n",
      "Epoch [216] ðŸ“Š acc: 0.947 | Targets: 0.8405 | Entropy: -1.8651\n",
      "New ref model saved\n",
      "Epoch [217] ðŸ“Š acc: 0.946 | Targets: 0.8462 | Entropy: -1.8688\n",
      "Epoch [218] ðŸ“Š acc: 0.948 | Targets: 0.8421 | Entropy: -1.8676\n",
      "New ref model saved\n",
      "Epoch [219] ðŸ“Š acc: 0.946 | Targets: 0.8447 | Entropy: -1.8691\n",
      "Epoch [220] ðŸ“Š acc: 0.946 | Targets: 0.8477 | Entropy: -1.8703\n",
      "\n",
      "Evaluating at epoch 220 â€¦\n",
      "Train Accuracy: 94.66%\n",
      "Train Average Loss: 0.8426\n",
      "Test Accuracy: 93.33%\n",
      "Test Average Loss: 0.8580\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 1.66e-04\n",
      "Epoch [221] ðŸ“Š acc: 0.946 | Targets: 0.8469 | Entropy: -1.8699\n",
      "Epoch [222] ðŸ“Š acc: 0.948 | Targets: 0.8418 | Entropy: -1.8686\n",
      "New ref model saved\n",
      "Epoch [223] ðŸ“Š acc: 0.947 | Targets: 0.8468 | Entropy: -1.8711\n",
      "Epoch [224] ðŸ“Š acc: 0.947 | Targets: 0.8454 | Entropy: -1.8710\n",
      "Epoch [225] ðŸ“Š acc: 0.948 | Targets: 0.8435 | Entropy: -1.8701\n",
      "Epoch [226] ðŸ“Š acc: 0.948 | Targets: 0.8434 | Entropy: -1.8695\n",
      "Epoch [227] ðŸ“Š acc: 0.948 | Targets: 0.8439 | Entropy: -1.8696\n",
      "Epoch [228] ðŸ“Š acc: 0.950 | Targets: 0.8408 | Entropy: -1.8688\n",
      "New ref model saved\n",
      "Epoch [229] ðŸ“Š acc: 0.949 | Targets: 0.8325 | Entropy: -1.8602\n",
      "Epoch [230] ðŸ“Š acc: 0.950 | Targets: 0.8324 | Entropy: -1.8610\n",
      "\n",
      "Evaluating at epoch 230 â€¦\n",
      "Train Accuracy: 94.91%\n",
      "Train Average Loss: 0.8337\n",
      "Test Accuracy: 93.55%\n",
      "Test Average Loss: 0.8533\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 1.29e-04\n",
      "Epoch [231] ðŸ“Š acc: 0.951 | Targets: 0.8315 | Entropy: -1.8609\n",
      "New ref model saved\n",
      "Epoch [232] ðŸ“Š acc: 0.950 | Targets: 0.8339 | Entropy: -1.8621\n",
      "Epoch [233] ðŸ“Š acc: 0.950 | Targets: 0.8348 | Entropy: -1.8630\n",
      "Epoch [234] ðŸ“Š acc: 0.951 | Targets: 0.8308 | Entropy: -1.8621\n",
      "New ref model saved\n",
      "Epoch [235] ðŸ“Š acc: 0.949 | Targets: 0.8442 | Entropy: -1.8729\n",
      "Epoch [236] ðŸ“Š acc: 0.952 | Targets: 0.8386 | Entropy: -1.8707\n",
      "New ref model saved\n",
      "Epoch [237] ðŸ“Š acc: 0.951 | Targets: 0.8390 | Entropy: -1.8694\n",
      "Epoch [238] ðŸ“Š acc: 0.950 | Targets: 0.8400 | Entropy: -1.8692\n",
      "Epoch [239] ðŸ“Š acc: 0.951 | Targets: 0.8384 | Entropy: -1.8688\n",
      "Epoch [240] ðŸ“Š acc: 0.951 | Targets: 0.8371 | Entropy: -1.8681\n",
      "\n",
      "Evaluating at epoch 240 â€¦\n",
      "Train Accuracy: 95.16%\n",
      "Train Average Loss: 0.8375\n",
      "Test Accuracy: 93.69%\n",
      "Test Average Loss: 0.8556\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 9.64e-05\n",
      "Epoch [241] ðŸ“Š acc: 0.951 | Targets: 0.8377 | Entropy: -1.8684\n",
      "Epoch [242] ðŸ“Š acc: 0.952 | Targets: 0.8351 | Entropy: -1.8671\n",
      "New ref model saved\n",
      "Epoch [243] ðŸ“Š acc: 0.952 | Targets: 0.8328 | Entropy: -1.8647\n",
      "Epoch [244] ðŸ“Š acc: 0.953 | Targets: 0.8325 | Entropy: -1.8645\n",
      "New ref model saved\n",
      "Epoch [245] ðŸ“Š acc: 0.951 | Targets: 0.8365 | Entropy: -1.8668\n",
      "Epoch [246] ðŸ“Š acc: 0.952 | Targets: 0.8340 | Entropy: -1.8659\n",
      "Epoch [247] ðŸ“Š acc: 0.954 | Targets: 0.8306 | Entropy: -1.8649\n",
      "New ref model saved\n",
      "Epoch [248] ðŸ“Š acc: 0.953 | Targets: 0.8336 | Entropy: -1.8656\n",
      "Epoch [249] ðŸ“Š acc: 0.953 | Targets: 0.8325 | Entropy: -1.8652\n",
      "Epoch [250] ðŸ“Š acc: 0.954 | Targets: 0.8293 | Entropy: -1.8643\n",
      "\n",
      "Evaluating at epoch 250 â€¦\n",
      "Train Accuracy: 95.27%\n",
      "Train Average Loss: 0.8332\n",
      "Test Accuracy: 93.71%\n",
      "Test Average Loss: 0.8541\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 6.79e-05\n",
      "Epoch [251] ðŸ“Š acc: 0.953 | Targets: 0.8322 | Entropy: -1.8653\n",
      "Epoch [252] ðŸ“Š acc: 0.952 | Targets: 0.8328 | Entropy: -1.8653\n",
      "Epoch [253] ðŸ“Š acc: 0.952 | Targets: 0.8346 | Entropy: -1.8657\n",
      "Epoch [254] ðŸ“Š acc: 0.954 | Targets: 0.8316 | Entropy: -1.8656\n",
      "Epoch [255] ðŸ“Š acc: 0.955 | Targets: 0.8290 | Entropy: -1.8645\n",
      "New ref model saved\n",
      "Epoch [256] ðŸ“Š acc: 0.954 | Targets: 0.8305 | Entropy: -1.8635\n",
      "Epoch [257] ðŸ“Š acc: 0.953 | Targets: 0.8304 | Entropy: -1.8632\n",
      "Epoch [258] ðŸ“Š acc: 0.954 | Targets: 0.8297 | Entropy: -1.8638\n",
      "Epoch [259] ðŸ“Š acc: 0.953 | Targets: 0.8302 | Entropy: -1.8636\n",
      "Epoch [260] ðŸ“Š acc: 0.955 | Targets: 0.8266 | Entropy: -1.8623\n",
      "\n",
      "Evaluating at epoch 260 â€¦\n",
      "Train Accuracy: 95.51%\n",
      "Train Average Loss: 0.8246\n",
      "Test Accuracy: 93.98%\n",
      "Test Average Loss: 0.8488\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 4.42e-05\n",
      "New best model saved with test accuracy: 93.98%\n",
      "Epoch [261] ðŸ“Š acc: 0.955 | Targets: 0.8269 | Entropy: -1.8630\n",
      "Epoch [262] ðŸ“Š acc: 0.955 | Targets: 0.8272 | Entropy: -1.8629\n",
      "New ref model saved\n",
      "Epoch [263] ðŸ“Š acc: 0.955 | Targets: 0.8255 | Entropy: -1.8610\n",
      "Epoch [264] ðŸ“Š acc: 0.957 | Targets: 0.8219 | Entropy: -1.8600\n",
      "New ref model saved\n",
      "Epoch [265] ðŸ“Š acc: 0.954 | Targets: 0.8251 | Entropy: -1.8609\n",
      "Epoch [266] ðŸ“Š acc: 0.956 | Targets: 0.8249 | Entropy: -1.8611\n",
      "Epoch [267] ðŸ“Š acc: 0.954 | Targets: 0.8275 | Entropy: -1.8617\n",
      "Epoch [268] ðŸ“Š acc: 0.955 | Targets: 0.8256 | Entropy: -1.8613\n",
      "Epoch [269] ðŸ“Š acc: 0.955 | Targets: 0.8253 | Entropy: -1.8612\n",
      "Epoch [270] ðŸ“Š acc: 0.953 | Targets: 0.8270 | Entropy: -1.8618\n",
      "\n",
      "Evaluating at epoch 270 â€¦\n",
      "Train Accuracy: 95.50%\n",
      "Train Average Loss: 0.8277\n",
      "Test Accuracy: 93.98%\n",
      "Test Average Loss: 0.8491\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 2.54e-05\n",
      "Epoch [271] ðŸ“Š acc: 0.954 | Targets: 0.8260 | Entropy: -1.8615\n",
      "Epoch [272] ðŸ“Š acc: 0.956 | Targets: 0.8234 | Entropy: -1.8608\n",
      "Epoch [273] ðŸ“Š acc: 0.955 | Targets: 0.8256 | Entropy: -1.8616\n",
      "Epoch [274] ðŸ“Š acc: 0.956 | Targets: 0.8245 | Entropy: -1.8612\n",
      "Epoch [275] ðŸ“Š acc: 0.956 | Targets: 0.8237 | Entropy: -1.8613\n",
      "Epoch [276] ðŸ“Š acc: 0.954 | Targets: 0.8259 | Entropy: -1.8615\n",
      "Epoch [277] ðŸ“Š acc: 0.955 | Targets: 0.8242 | Entropy: -1.8615\n",
      "Epoch [278] ðŸ“Š acc: 0.956 | Targets: 0.8242 | Entropy: -1.8616\n",
      "Epoch [279] ðŸ“Š acc: 0.958 | Targets: 0.8214 | Entropy: -1.8606\n",
      "New ref model saved\n",
      "Epoch [280] ðŸ“Š acc: 0.956 | Targets: 0.8238 | Entropy: -1.8616\n",
      "\n",
      "Evaluating at epoch 280 â€¦\n",
      "Train Accuracy: 95.64%\n",
      "Train Average Loss: 0.8242\n",
      "Test Accuracy: 93.99%\n",
      "Test Average Loss: 0.8484\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 1.19e-05\n",
      "New best model saved with test accuracy: 93.99%\n",
      "Epoch [281] ðŸ“Š acc: 0.954 | Targets: 0.8286 | Entropy: -1.8632\n",
      "Epoch [282] ðŸ“Š acc: 0.958 | Targets: 0.8223 | Entropy: -1.8621\n",
      "New ref model saved\n",
      "Epoch [283] ðŸ“Š acc: 0.956 | Targets: 0.8279 | Entropy: -1.8652\n",
      "Epoch [284] ðŸ“Š acc: 0.957 | Targets: 0.8287 | Entropy: -1.8668\n",
      "Epoch [285] ðŸ“Š acc: 0.956 | Targets: 0.8286 | Entropy: -1.8667\n",
      "Epoch [286] ðŸ“Š acc: 0.957 | Targets: 0.8263 | Entropy: -1.8658\n",
      "Epoch [287] ðŸ“Š acc: 0.956 | Targets: 0.8298 | Entropy: -1.8669\n",
      "Epoch [288] ðŸ“Š acc: 0.956 | Targets: 0.8295 | Entropy: -1.8667\n",
      "Epoch [289] ðŸ“Š acc: 0.956 | Targets: 0.8294 | Entropy: -1.8667\n",
      "Epoch [290] ðŸ“Š acc: 0.956 | Targets: 0.8290 | Entropy: -1.8671\n",
      "\n",
      "Evaluating at epoch 290 â€¦\n",
      "Train Accuracy: 95.58%\n",
      "Train Average Loss: 0.8294\n",
      "Test Accuracy: 93.96%\n",
      "Test Average Loss: 0.8532\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 3.74e-06\n",
      "Epoch [291] ðŸ“Š acc: 0.955 | Targets: 0.8309 | Entropy: -1.8670\n",
      "Epoch [292] ðŸ“Š acc: 0.956 | Targets: 0.8292 | Entropy: -1.8668\n",
      "Epoch [293] ðŸ“Š acc: 0.955 | Targets: 0.8295 | Entropy: -1.8669\n",
      "Epoch [294] ðŸ“Š acc: 0.955 | Targets: 0.8305 | Entropy: -1.8668\n",
      "Epoch [295] ðŸ“Š acc: 0.955 | Targets: 0.8301 | Entropy: -1.8666\n",
      "Epoch [296] ðŸ“Š acc: 0.956 | Targets: 0.8286 | Entropy: -1.8666\n",
      "Epoch [297] ðŸ“Š acc: 0.955 | Targets: 0.8309 | Entropy: -1.8671\n",
      "Epoch [298] ðŸ“Š acc: 0.956 | Targets: 0.8292 | Entropy: -1.8672\n",
      "Epoch [299] ðŸ“Š acc: 0.955 | Targets: 0.8307 | Entropy: -1.8675\n",
      "Epoch [300] ðŸ“Š acc: 0.956 | Targets: 0.8287 | Entropy: -1.8665\n",
      "\n",
      "Evaluating at epoch 300 â€¦\n",
      "Train Accuracy: 95.54%\n",
      "Train Average Loss: 0.8304\n",
      "Test Accuracy: 94.04%\n",
      "Test Average Loss: 0.8523\n",
      "Total Trainable Parameters: 515,754\n",
      "\n",
      "Current learning rate: 1.00e-06\n",
      "New best model saved with test accuracy: 94.04%\n",
      "Finished Training\n",
      "Best test accuracy achieved: 94.04%\n",
      "Total Trainable Parameters: 515,754\n"
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "net = Net()\n",
    "train_model(net, get_cifar10_loaders, evaluate_model)\n",
    "\n",
    "model = Net()\n",
    "print(f\"Total Trainable Parameters: {count_parameters(model):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
